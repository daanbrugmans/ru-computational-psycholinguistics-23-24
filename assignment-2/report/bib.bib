@article{fitz2019erp,
    title = {Language ERPs reflect learning through prediction error propagation},
    journal = {Cognitive Psychology},
    volume = {111},
    pages = {15-52},
    year = {2019},
    issn = {0010-0285},
    doi = {https://doi.org/10.1016/j.cogpsych.2019.03.002},
    url = {https://www.sciencedirect.com/science/article/pii/S0010028518300124},
    author = {Hartmut Fitz and Franklin Chang}
}

@misc{frank2024gradients,
 title={Neural language model gradients predict event-related brain potentials},
 url={osf.io/preprints/psyarxiv/cx3h6},
 DOI={10.31234/osf.io/cx3h6},
 publisher={PsyArXiv},
 author={Frank, Stefan L},
 year={2024},
 month={Jan}
}

@article{kim2005combinatory,
    title = {The independence of combinatory semantic processing: Evidence from event-related potentials},
    journal = {Journal of Memory and Language},
    volume = {52},
    number = {2},
    pages = {205-225},
    year = {2005},
    issn = {0749-596X},
    doi = {https://doi.org/10.1016/j.jml.2004.10.002},
    url = {https://www.sciencedirect.com/science/article/pii/S0749596X04001159},
    author = {Albert Kim and Lee Osterhout}
}

@article{oh2023why,
    author = {Oh, Byung-Doh and Schuler, William},
    title = "{Why Does Surprisal From Larger Transformer-Based Language Models Provide a Poorer Fit to Human Reading Times?}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {11},
    pages = {336-350},
    year = {2023},
    month = {03},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00548},
    url = {https://doi.org/10.1162/tacl\_a\_00548},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00548/2075940/tacl\_a\_00548.pdf},
}